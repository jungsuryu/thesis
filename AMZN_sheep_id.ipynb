{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.model_selection import train_test_split, ParameterGrid\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from scipy.stats import pearsonr\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(action = 'ignore')\n",
    "\n",
    "import pickle\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# 데이터 불러오기\n",
    "ratings = pd.read_csv('/home/ryu/thesis/data/amazon/Amazon_ratings.csv')\n",
    "reviews = pd.read_csv('/home/ryu/thesis/data/amazon/Amazon_reviews.csv')\n",
    "\n",
    "ratings = ratings[['item_id', 'user_id', 'rating']]\n",
    "reviews = reviews[['item_id', 'user_id', 'text']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(241861, 3)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 데이터 분할을 보장하기 위해 3개 이하로 평가한 사용자의 데이터는 콜드 스타트(Cold Start) 사례로 간주 하고 제거\n",
    "cnt = ratings.groupby('user_id').count()['rating']\n",
    "# cnt[cnt<=3] # 9.065%\n",
    "keys = cnt[cnt>3].keys()\n",
    "ratings = ratings[ratings['user_id'].isin(keys)]\n",
    "ratings.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 리뷰 임베딩 데이터 불러오기\n",
    "with open('/home/ryu/thesis/real_amazon/additional_var/sbert_emb.pickle', 'rb') as f:\n",
    "    embeddings = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "emb = pd.DataFrame(embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.merge(ratings, reviews, how='left', left_on=['user_id', 'item_id'], right_on=['user_id', 'item_id'])\n",
    "data = pd.concat([data, emb], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Encoding dictionaries\n",
    "def create_encoding_dict(feature, start_point):\n",
    "    feature_dict = {}\n",
    "    for value in set(feature):\n",
    "        feature_dict[value] = start_point + len(feature_dict)\n",
    "    return feature_dict, start_point + len(feature_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of Users: 17355\n",
      "Number of Items: 17244\n",
      "전체 특성 수: 34983\n"
     ]
    }
   ],
   "source": [
    "# 사용자, 아이템, 직업, 성별 인코딩\n",
    "user_dict, start_point = create_encoding_dict(data['user_id'], 0)\n",
    "item_dict, start_point = create_encoding_dict(data['item_id'], start_point)\n",
    "\n",
    "# 텍스트 임베딩\n",
    "text_index = start_point\n",
    "start_point += 384\n",
    "\n",
    "# 전체 특성 수 계산\n",
    "num_x = start_point\n",
    "\n",
    "# 각 특성의 개수 출력 (선택적)\n",
    "print(f\"Number of Users: {len(user_dict)}\")\n",
    "print(f\"Number of Items: {len(item_dict)}\")\n",
    "print(f\"전체 특성 수: {num_x}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = data.copy()\n",
    "y = data['user_id']\n",
    "ratings_train, ratings_test = train_test_split(x, test_size=0.25, stratify=y, random_state=8)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# baseline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train set 평점의 평균값 -> 타겟 변수에서 빼서 평균 평점에 대한 보정 진행\n",
    "w0 = np.mean(ratings_train['rating'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def encode_data(input, bias, user_dict, item_dict, embeddings_start_idx):\n",
    "    data = []\n",
    "    target = []\n",
    "\n",
    "    for i in range(len(input)):\n",
    "        ea_case = input.iloc[i]\n",
    "        x_index = []\n",
    "        x_value = []\n",
    "\n",
    "        # user id encoding\n",
    "        x_index.append(user_dict[ea_case['user_id']])\n",
    "        x_value.append(1.)\n",
    "\n",
    "        # item id encoding\n",
    "        x_index.append(item_dict[ea_case['item_id']])\n",
    "        x_value.append(1.)\n",
    "        \n",
    "        # review encoding\n",
    "        review_embed = ea_case[-384:]        # 해당 리뷰의 임베딩\n",
    "        for j in range(384):\n",
    "            x_index.append(embeddings_start_idx+j)\n",
    "            x_value.append(review_embed[j])\n",
    "\n",
    "        # target encoding\n",
    "        data.append([x_index, x_value])\n",
    "        target.append(ea_case['rating']-bias)\n",
    "\n",
    "        # 진행 상황 출력\n",
    "        if (i % 30000) == 0:\n",
    "            print('Encoding ', i, 'cases...')\n",
    "    \n",
    "    return data, target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Encoding Train Set\n",
      "Encoding  0 cases...\n",
      "Encoding  30000 cases...\n",
      "Encoding  60000 cases...\n",
      "Encoding  90000 cases...\n",
      "Encoding  120000 cases...\n",
      "Encoding  150000 cases...\n",
      "Encoding  180000 cases...\n",
      "Encoding Test Set\n",
      "Encoding  0 cases...\n",
      "Encoding  30000 cases...\n",
      "Encoding  60000 cases...\n"
     ]
    }
   ],
   "source": [
    "print('Encoding Train Set')\n",
    "train_data, train_target = encode_data(ratings_train, w0, user_dict, item_dict, text_index)\n",
    "print('Encoding Test Set')\n",
    "test_data, test_target = encode_data(ratings_test, w0, user_dict, item_dict, text_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def RMSE(y_true, y_pred):\n",
    "    return np.sqrt(np.mean((np.array(y_true) - np.array(y_pred))**2))\n",
    "\n",
    "class FM():\n",
    "    def __init__(self, N, K, train_x, train_y, test_x, test_y, alpha, beta, iterations=100, tolerance=0.005, l2_reg=True, verbose=True): # 초기화\n",
    "        self.K = K                          # Number of latent factors\n",
    "        self.N = N                          # Number of x (variables)\n",
    "        self.alpha = alpha\n",
    "        self.beta = beta\n",
    "        self.iterations = iterations\n",
    "        self.l2_reg = l2_reg\n",
    "        self.tolerance = tolerance\n",
    "        self.verbose = verbose\n",
    "\n",
    "        # w와 v 초기화\n",
    "        self.w = np.random.normal(scale=1./self.N, size=(self.N)) # 사이즈는 변수의 수만큼. 변수마다 bias 하나\n",
    "        self.v = np.random.normal(scale=1./self.K, size=(self.N, self.K)) # 변수의 수 * K\n",
    "\n",
    "        # Train/Test 분리\n",
    "        self.train_x = train_x\n",
    "        self.test_x = test_x\n",
    "        self.train_y = train_y\n",
    "        self.test_y = test_y\n",
    "\n",
    "    def test(self):                                     # Training 하면서 RMSE 계산 \n",
    "        # SGD를 iterations 숫자만큼 수행\n",
    "        best_RMSE = float('inf') # stop 위해\n",
    "        best_iteration = 0\n",
    "        training_process = []\n",
    "        for i in range(self.iterations): # 600번\n",
    "            rmse1 = self.sgd(self.train_x, self.train_y)        # SGD & Train RMSE 계산\n",
    "            rmse2 = self.test_rmse(self.test_x, self.test_y)    # Test RMSE 계산     \n",
    "            training_process.append((i, rmse1, rmse2))\n",
    "            if self.verbose:\n",
    "                if (i+1) % 10 == 0:\n",
    "                    print(\"Iteration: %d ; Train RMSE = %.6f ; Test RMSE = %.6f\" % (i+1, rmse1, rmse2))\n",
    "            if best_RMSE > rmse2:                       # New best record\n",
    "                best_RMSE = rmse2\n",
    "                best_iteration = i\n",
    "            elif (rmse2 - best_RMSE) > self.tolerance:  # RMSE is increasing over tolerance\n",
    "                break\n",
    "        print(best_iteration, best_RMSE)\n",
    "        return training_process\n",
    "        \n",
    "    # w, v 업데이트를 위한 Stochastic gradient descent \n",
    "    def sgd(self, x_data, y_data):\n",
    "        y_pred = []\n",
    "        for data, y in zip(x_data, y_data): # 100,000번. x_data, y_data가 100,000개\n",
    "            x_idx = data[0] # 데이터의 첫번째 (x_index, x_value)에 대한 인덱스 받아옴\n",
    "            x_0 = np.array(data[1])     # xi axis=0 [1, 2, 3] (1차원)\n",
    "            x_1 = x_0.reshape(-1, 1)    # xi axis=1 [[1], [2], [3]] (2차원: V matrix와 계산 위해서)\n",
    "    \n",
    "            # biases\n",
    "            bias_score = np.sum(self.w[x_idx] * x_0) # 여기선 x_0를 1차원으로 사용. w matrix는 1차원이기 때문\n",
    "    \n",
    "            # score 계산\n",
    "            vx = self.v[x_idx] * (x_1)          # v matrix * x (브로드캐스팅)\n",
    "            sum_vx = np.sum(vx, axis=0)         # sigma(vx): 칼럼으로 쭉 더한 것 (element K개 (=350개))\n",
    "            sum_vx_2 = np.sum(vx * vx, axis=0)  # ( v matrix * x )의 제곱: element 350개\n",
    "            latent_score = 0.5 * np.sum(np.square(sum_vx) - sum_vx_2)\n",
    "\n",
    "            # 예측값 계산\n",
    "            y_hat = bias_score + latent_score # bias까지 더하면 최종 예측값 (전체 평균은 전에 뺐기 때문에 따로 또 빼주지 않음)\n",
    "            y_pred.append(y_hat) # y_pred 75,000개 (아까 train,test 분리함)\n",
    "            error = y - y_hat # 에러 구했으니까 아래에서 업데이트 가능\n",
    "            # w, v 업데이트 (week 7 수업자료에 있는 update rule)\n",
    "            if self.l2_reg:     # regularization이 있는 경우\n",
    "                self.w[x_idx] += error * self.alpha * (x_0 - self.beta * self.w[x_idx])\n",
    "                self.v[x_idx] += error * self.alpha * ((x_1) * sum(vx) - (vx * x_1) - self.beta * self.v[x_idx])\n",
    "            else:               # regularization이 없는 경우\n",
    "                self.w[x_idx] += error * self.alpha * x_0\n",
    "                self.v[x_idx] += error * self.alpha * ((x_1) * sum(vx) - (vx * x_1))\n",
    "        return RMSE(y_data, y_pred) \n",
    "\n",
    "    def test_rmse(self, x_data, y_data): # test set에 대한 RMSE\n",
    "        y_pred = []\n",
    "        for data , y in zip(x_data, y_data):\n",
    "            y_hat = self.predict(data[0], data[1])\n",
    "            y_pred.append(y_hat)\n",
    "        return RMSE(y_data, y_pred)\n",
    "\n",
    "    def predict(self, idx, x):\n",
    "        x_0 = np.array(x)\n",
    "        x_1 = x_0.reshape(-1, 1)\n",
    "\n",
    "        # biases\n",
    "        bias_score = np.sum(self.w[idx] * x_0)\n",
    "\n",
    "        # score 계산\n",
    "        vx = self.v[idx] * (x_1)\n",
    "        sum_vx = np.sum(vx, axis=0)\n",
    "        sum_vx_2 = np.sum(vx * vx, axis=0)\n",
    "        latent_score = 0.5 * np.sum(np.square(sum_vx) - sum_vx_2)\n",
    "\n",
    "        # 예측값 계산\n",
    "        y_hat = bias_score + latent_score\n",
    "        return y_hat\n",
    "\n",
    "    def predict_one(self, user_id, movie_id):\n",
    "        x_idx = np.array([user_dict[user_id], item_dict[movie_id]])\n",
    "        x_data = np.array([1, 1])\n",
    "        return self.predict(x_idx, x_data) + w0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Open saved model\n",
    "with open('/home/ryu/thesis/real_amazon/additional_var/2_trained_models/FM_model8.pkl', 'rb') as f:\n",
    "    model = pickle.load(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# black sheep identification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 공통 아이템 수 계산 함수\n",
    "def calculate_common_items(ratings):\n",
    "    user_items = ratings.groupby('user_id')['item_id'].apply(set)\n",
    "    common_items_count = {user: {} for user in user_items.keys()}\n",
    "\n",
    "    for user1 in user_items.keys():\n",
    "        for user2 in user_items.keys():\n",
    "            if user1 != user2:  # 중복 계산 방지\n",
    "                common_items = user_items[user1].intersection(user_items[user2])\n",
    "                common_items_count[user1][user2] = len(common_items)\n",
    "                \n",
    "    return common_items_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "common_items_train = calculate_common_items(ratings_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 모든 사용자 쌍의 공통 아이템 수를 평균값 분포\n",
    "average_common_items = [sum(inner_dict.values())/len(inner_dict) for inner_dict in common_items_train.values() if len(inner_dict)!=0]\n",
    "pd.Series(average_common_items).describe(percentiles=[0.05, 0.1, 0.2, 0.25, 0.3, 0.4, 0.5, 0.6, 0.7, 0.75, 0.8])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('AMZN_train_common_items.pkl', 'rb') as f:\n",
    "    common_items_count = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('AMZN_all_common_items_cnt.pkl', 'wb') as f:\n",
    "    pickle.dump(common_items_count_all, f)\n",
    "with open('AMZN_train_common_items.pkl', 'wb') as f:\n",
    "    pickle.dump(common_items_train, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def black(common_items_count, max_common_items, min_users):\n",
    "\n",
    "    user_count = {}\n",
    "\n",
    "    for user1, others in common_items_count.items():\n",
    "        user_count[user1] = sum(1 for user2, count in others.items() if count >= max_common_items)\n",
    "\n",
    "    qualifying_users = [user for user, count in user_count.items() if count < min_users]\n",
    "\n",
    "    return qualifying_users"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "black_id = black(common_items_count, 2, 1)\n",
    "len(black_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ratings.user_id.nunique()-len(black_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# with open('black_id.pkl', 'wb') as f:\n",
    "#     pickle.dump(black_id, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('/home/ryu/thesis/real_amazon/black_id.pkl', 'rb') as f:\n",
    "    black = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ratings_train = ratings_train[~ratings_train['user_id'].isin(black)]\n",
    "# ratings_test = ratings_test[~ratings_test['user_id'].isin(black)]\n",
    "# ratings = ratings[~ratings['user_id'].isin(black)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# similarity calculation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_user_latent_matrix(model, user_dict):\n",
    "    user_latent_matrix = {}\n",
    "    for user_id in user_dict:\n",
    "        user_index = user_dict[user_id]             # 사용자 ID를 인덱스로 변환\n",
    "        user_latent_vector = model.v[user_index]    # 잠재 벡터 추출\n",
    "        user_latent_matrix[user_id] = user_latent_vector\n",
    "    return user_latent_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_latent_matrix = extract_user_latent_matrix(model, user_dict)\n",
    "user_latent_matrix = pd.DataFrame(user_latent_matrix).T\n",
    "user_latent_matrix = user_latent_matrix.drop(black, errors='ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 사용자 간 유사도 (피어슨 상관계수) \n",
    "def pearson_similarity(user_latent_vectors):\n",
    "    num_users = user_latent_vectors.shape[0]\n",
    "    similarity_matrix = np.zeros((num_users, num_users))\n",
    "    \n",
    "    for i in range(num_users):\n",
    "        for j in range(i, num_users):\n",
    "            if np.all(user_latent_vectors[i] == 0) or np.all(user_latent_vectors[j] == 0):\n",
    "                # If a user's latent vector is all zeros, set similarity to 0\n",
    "                similarity = 0\n",
    "            else:\n",
    "                similarity, _ = pearsonr(user_latent_vectors[i], user_latent_vectors[j])\n",
    "            \n",
    "            similarity_matrix[i, j] = similarity\n",
    "            similarity_matrix[j, i] = similarity  # Pearson correlation is symmetric\n",
    "    \n",
    "    return similarity_matrix\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 모든 사용자 쌍에 대한 [피어슨 상관계수] 계산\n",
    "# user_latent_vectors = model.P\n",
    "# user_latent_vectors = pd.DataFrame(model.P, index=model.index_user_id.values())\n",
    "# user_latent_vectors = user_latent_vectors.drop(black_id, errors='ignore')\n",
    "user_latent_vectors = user_latent_matrix.to_numpy()\n",
    "pearson_matrix = pearson_similarity(user_latent_vectors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>B00BJUE88U</th>\n",
       "      <th>B004CLYJ2I</th>\n",
       "      <th>B0047FHOWG</th>\n",
       "      <th>B01GVSD3P8</th>\n",
       "      <th>B00MRL30N4</th>\n",
       "      <th>B0043RS864</th>\n",
       "      <th>B00O23IQ66</th>\n",
       "      <th>B01FLKIT4M</th>\n",
       "      <th>B005JLQL26</th>\n",
       "      <th>B00005N5WU</th>\n",
       "      <th>...</th>\n",
       "      <th>B00DZDWMQO</th>\n",
       "      <th>B00WJOVCOS</th>\n",
       "      <th>B00PLMN77K</th>\n",
       "      <th>B00K9HID1C</th>\n",
       "      <th>B007IJ7T4G</th>\n",
       "      <th>B00005T3Q2</th>\n",
       "      <th>B000UXZUZC</th>\n",
       "      <th>B00A3YDYMO</th>\n",
       "      <th>B007EZPLFS</th>\n",
       "      <th>B00KG8K5CY</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>B00BJUE88U</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.226897</td>\n",
       "      <td>0.536480</td>\n",
       "      <td>0.136809</td>\n",
       "      <td>-0.410368</td>\n",
       "      <td>0.453023</td>\n",
       "      <td>0.233356</td>\n",
       "      <td>-0.379906</td>\n",
       "      <td>-0.282338</td>\n",
       "      <td>0.298479</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.471349</td>\n",
       "      <td>-0.044048</td>\n",
       "      <td>0.111372</td>\n",
       "      <td>0.239136</td>\n",
       "      <td>0.237142</td>\n",
       "      <td>0.446691</td>\n",
       "      <td>-0.435374</td>\n",
       "      <td>-0.326088</td>\n",
       "      <td>-0.395481</td>\n",
       "      <td>-0.233285</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>B004CLYJ2I</th>\n",
       "      <td>0.226897</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.196737</td>\n",
       "      <td>0.116811</td>\n",
       "      <td>-0.106415</td>\n",
       "      <td>0.011693</td>\n",
       "      <td>0.053132</td>\n",
       "      <td>-0.053271</td>\n",
       "      <td>0.004096</td>\n",
       "      <td>-0.018750</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.128175</td>\n",
       "      <td>0.003443</td>\n",
       "      <td>0.040447</td>\n",
       "      <td>0.168422</td>\n",
       "      <td>-0.007217</td>\n",
       "      <td>0.166299</td>\n",
       "      <td>-0.160315</td>\n",
       "      <td>-0.064352</td>\n",
       "      <td>-0.159944</td>\n",
       "      <td>0.077789</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>B0047FHOWG</th>\n",
       "      <td>0.536480</td>\n",
       "      <td>0.196737</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.053088</td>\n",
       "      <td>-0.555178</td>\n",
       "      <td>0.475562</td>\n",
       "      <td>0.377427</td>\n",
       "      <td>-0.314111</td>\n",
       "      <td>-0.215811</td>\n",
       "      <td>0.258964</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.557110</td>\n",
       "      <td>-0.097033</td>\n",
       "      <td>0.269555</td>\n",
       "      <td>0.348854</td>\n",
       "      <td>0.191020</td>\n",
       "      <td>0.526564</td>\n",
       "      <td>-0.475494</td>\n",
       "      <td>-0.360447</td>\n",
       "      <td>-0.597356</td>\n",
       "      <td>-0.122929</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>B01GVSD3P8</th>\n",
       "      <td>0.136809</td>\n",
       "      <td>0.116811</td>\n",
       "      <td>0.053088</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.118557</td>\n",
       "      <td>0.025855</td>\n",
       "      <td>0.146969</td>\n",
       "      <td>-0.216768</td>\n",
       "      <td>-0.269778</td>\n",
       "      <td>-0.037508</td>\n",
       "      <td>...</td>\n",
       "      <td>0.161941</td>\n",
       "      <td>-0.101202</td>\n",
       "      <td>-0.326541</td>\n",
       "      <td>0.025201</td>\n",
       "      <td>0.195212</td>\n",
       "      <td>0.256277</td>\n",
       "      <td>-0.095160</td>\n",
       "      <td>-0.256166</td>\n",
       "      <td>-0.199663</td>\n",
       "      <td>-0.237844</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>B00MRL30N4</th>\n",
       "      <td>-0.410368</td>\n",
       "      <td>-0.106415</td>\n",
       "      <td>-0.555178</td>\n",
       "      <td>-0.118557</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.491473</td>\n",
       "      <td>-0.278773</td>\n",
       "      <td>0.375204</td>\n",
       "      <td>0.255096</td>\n",
       "      <td>-0.209280</td>\n",
       "      <td>...</td>\n",
       "      <td>0.364615</td>\n",
       "      <td>0.172055</td>\n",
       "      <td>-0.056057</td>\n",
       "      <td>-0.188795</td>\n",
       "      <td>-0.307583</td>\n",
       "      <td>-0.462337</td>\n",
       "      <td>0.454268</td>\n",
       "      <td>0.396735</td>\n",
       "      <td>0.436341</td>\n",
       "      <td>0.276200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>B00005T3Q2</th>\n",
       "      <td>0.446691</td>\n",
       "      <td>0.166299</td>\n",
       "      <td>0.526564</td>\n",
       "      <td>0.256277</td>\n",
       "      <td>-0.462337</td>\n",
       "      <td>0.423980</td>\n",
       "      <td>0.390470</td>\n",
       "      <td>-0.440213</td>\n",
       "      <td>-0.254376</td>\n",
       "      <td>0.206916</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.378210</td>\n",
       "      <td>-0.177677</td>\n",
       "      <td>-0.006729</td>\n",
       "      <td>0.330972</td>\n",
       "      <td>0.357840</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.433884</td>\n",
       "      <td>-0.439033</td>\n",
       "      <td>-0.555242</td>\n",
       "      <td>-0.299944</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>B000UXZUZC</th>\n",
       "      <td>-0.435374</td>\n",
       "      <td>-0.160315</td>\n",
       "      <td>-0.475494</td>\n",
       "      <td>-0.095160</td>\n",
       "      <td>0.454268</td>\n",
       "      <td>-0.443395</td>\n",
       "      <td>-0.214233</td>\n",
       "      <td>0.369583</td>\n",
       "      <td>0.263889</td>\n",
       "      <td>-0.251675</td>\n",
       "      <td>...</td>\n",
       "      <td>0.395942</td>\n",
       "      <td>0.033876</td>\n",
       "      <td>-0.121735</td>\n",
       "      <td>-0.282371</td>\n",
       "      <td>-0.233755</td>\n",
       "      <td>-0.433884</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.341956</td>\n",
       "      <td>0.421697</td>\n",
       "      <td>0.202745</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>B00A3YDYMO</th>\n",
       "      <td>-0.326088</td>\n",
       "      <td>-0.064352</td>\n",
       "      <td>-0.360447</td>\n",
       "      <td>-0.256166</td>\n",
       "      <td>0.396735</td>\n",
       "      <td>-0.496108</td>\n",
       "      <td>-0.168579</td>\n",
       "      <td>0.419773</td>\n",
       "      <td>0.216586</td>\n",
       "      <td>-0.261095</td>\n",
       "      <td>...</td>\n",
       "      <td>0.314975</td>\n",
       "      <td>0.083285</td>\n",
       "      <td>0.025681</td>\n",
       "      <td>-0.106445</td>\n",
       "      <td>-0.324034</td>\n",
       "      <td>-0.439033</td>\n",
       "      <td>0.341956</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.450008</td>\n",
       "      <td>0.313734</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>B007EZPLFS</th>\n",
       "      <td>-0.395481</td>\n",
       "      <td>-0.159944</td>\n",
       "      <td>-0.597356</td>\n",
       "      <td>-0.199663</td>\n",
       "      <td>0.436341</td>\n",
       "      <td>-0.400687</td>\n",
       "      <td>-0.283346</td>\n",
       "      <td>0.455492</td>\n",
       "      <td>0.223197</td>\n",
       "      <td>-0.113864</td>\n",
       "      <td>...</td>\n",
       "      <td>0.366280</td>\n",
       "      <td>0.103176</td>\n",
       "      <td>-0.022115</td>\n",
       "      <td>-0.271353</td>\n",
       "      <td>-0.317245</td>\n",
       "      <td>-0.555242</td>\n",
       "      <td>0.421697</td>\n",
       "      <td>0.450008</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.161778</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>B00KG8K5CY</th>\n",
       "      <td>-0.233285</td>\n",
       "      <td>0.077789</td>\n",
       "      <td>-0.122929</td>\n",
       "      <td>-0.237844</td>\n",
       "      <td>0.276200</td>\n",
       "      <td>-0.437674</td>\n",
       "      <td>-0.174038</td>\n",
       "      <td>0.401352</td>\n",
       "      <td>0.255528</td>\n",
       "      <td>-0.350103</td>\n",
       "      <td>...</td>\n",
       "      <td>0.027350</td>\n",
       "      <td>0.057064</td>\n",
       "      <td>0.345951</td>\n",
       "      <td>-0.031449</td>\n",
       "      <td>-0.424218</td>\n",
       "      <td>-0.299944</td>\n",
       "      <td>0.202745</td>\n",
       "      <td>0.313734</td>\n",
       "      <td>0.161778</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>9631 rows × 9631 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            B00BJUE88U  B004CLYJ2I  B0047FHOWG  B01GVSD3P8  B00MRL30N4  \\\n",
       "B00BJUE88U    1.000000    0.226897    0.536480    0.136809   -0.410368   \n",
       "B004CLYJ2I    0.226897    1.000000    0.196737    0.116811   -0.106415   \n",
       "B0047FHOWG    0.536480    0.196737    1.000000    0.053088   -0.555178   \n",
       "B01GVSD3P8    0.136809    0.116811    0.053088    1.000000   -0.118557   \n",
       "B00MRL30N4   -0.410368   -0.106415   -0.555178   -0.118557    1.000000   \n",
       "...                ...         ...         ...         ...         ...   \n",
       "B00005T3Q2    0.446691    0.166299    0.526564    0.256277   -0.462337   \n",
       "B000UXZUZC   -0.435374   -0.160315   -0.475494   -0.095160    0.454268   \n",
       "B00A3YDYMO   -0.326088   -0.064352   -0.360447   -0.256166    0.396735   \n",
       "B007EZPLFS   -0.395481   -0.159944   -0.597356   -0.199663    0.436341   \n",
       "B00KG8K5CY   -0.233285    0.077789   -0.122929   -0.237844    0.276200   \n",
       "\n",
       "            B0043RS864  B00O23IQ66  B01FLKIT4M  B005JLQL26  B00005N5WU  ...  \\\n",
       "B00BJUE88U    0.453023    0.233356   -0.379906   -0.282338    0.298479  ...   \n",
       "B004CLYJ2I    0.011693    0.053132   -0.053271    0.004096   -0.018750  ...   \n",
       "B0047FHOWG    0.475562    0.377427   -0.314111   -0.215811    0.258964  ...   \n",
       "B01GVSD3P8    0.025855    0.146969   -0.216768   -0.269778   -0.037508  ...   \n",
       "B00MRL30N4   -0.491473   -0.278773    0.375204    0.255096   -0.209280  ...   \n",
       "...                ...         ...         ...         ...         ...  ...   \n",
       "B00005T3Q2    0.423980    0.390470   -0.440213   -0.254376    0.206916  ...   \n",
       "B000UXZUZC   -0.443395   -0.214233    0.369583    0.263889   -0.251675  ...   \n",
       "B00A3YDYMO   -0.496108   -0.168579    0.419773    0.216586   -0.261095  ...   \n",
       "B007EZPLFS   -0.400687   -0.283346    0.455492    0.223197   -0.113864  ...   \n",
       "B00KG8K5CY   -0.437674   -0.174038    0.401352    0.255528   -0.350103  ...   \n",
       "\n",
       "            B00DZDWMQO  B00WJOVCOS  B00PLMN77K  B00K9HID1C  B007IJ7T4G  \\\n",
       "B00BJUE88U   -0.471349   -0.044048    0.111372    0.239136    0.237142   \n",
       "B004CLYJ2I   -0.128175    0.003443    0.040447    0.168422   -0.007217   \n",
       "B0047FHOWG   -0.557110   -0.097033    0.269555    0.348854    0.191020   \n",
       "B01GVSD3P8    0.161941   -0.101202   -0.326541    0.025201    0.195212   \n",
       "B00MRL30N4    0.364615    0.172055   -0.056057   -0.188795   -0.307583   \n",
       "...                ...         ...         ...         ...         ...   \n",
       "B00005T3Q2   -0.378210   -0.177677   -0.006729    0.330972    0.357840   \n",
       "B000UXZUZC    0.395942    0.033876   -0.121735   -0.282371   -0.233755   \n",
       "B00A3YDYMO    0.314975    0.083285    0.025681   -0.106445   -0.324034   \n",
       "B007EZPLFS    0.366280    0.103176   -0.022115   -0.271353   -0.317245   \n",
       "B00KG8K5CY    0.027350    0.057064    0.345951   -0.031449   -0.424218   \n",
       "\n",
       "            B00005T3Q2  B000UXZUZC  B00A3YDYMO  B007EZPLFS  B00KG8K5CY  \n",
       "B00BJUE88U    0.446691   -0.435374   -0.326088   -0.395481   -0.233285  \n",
       "B004CLYJ2I    0.166299   -0.160315   -0.064352   -0.159944    0.077789  \n",
       "B0047FHOWG    0.526564   -0.475494   -0.360447   -0.597356   -0.122929  \n",
       "B01GVSD3P8    0.256277   -0.095160   -0.256166   -0.199663   -0.237844  \n",
       "B00MRL30N4   -0.462337    0.454268    0.396735    0.436341    0.276200  \n",
       "...                ...         ...         ...         ...         ...  \n",
       "B00005T3Q2    1.000000   -0.433884   -0.439033   -0.555242   -0.299944  \n",
       "B000UXZUZC   -0.433884    1.000000    0.341956    0.421697    0.202745  \n",
       "B00A3YDYMO   -0.439033    0.341956    1.000000    0.450008    0.313734  \n",
       "B007EZPLFS   -0.555242    0.421697    0.450008    1.000000    0.161778  \n",
       "B00KG8K5CY   -0.299944    0.202745    0.313734    0.161778    1.000000  \n",
       "\n",
       "[9631 rows x 9631 columns]"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 유사도 DataFrame으로 변환 (인덱스와 칼럼에 user_id 할당)\n",
    "# p_index = ratings[~ratings['user_id'].isin(black_id)]['user_id'].unique()\n",
    "pearson_df = pd.DataFrame(pearson_matrix, index=user_latent_matrix.index, columns=user_latent_matrix.index)\n",
    "pearson_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save model results\n",
    "with open('/home/ryu/thesis/real_amazon/additional_var/1_gsu_data/FM_8_pearson_sim.pkl', 'wb') as f:\n",
    "    pickle.dump(pearson_df, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>B00BJUE88U</th>\n",
       "      <th>B004CLYJ2I</th>\n",
       "      <th>B0047FHOWG</th>\n",
       "      <th>B01GVSD3P8</th>\n",
       "      <th>B00MRL30N4</th>\n",
       "      <th>B0043RS864</th>\n",
       "      <th>B00O23IQ66</th>\n",
       "      <th>B01FLKIT4M</th>\n",
       "      <th>B005JLQL26</th>\n",
       "      <th>B00005N5WU</th>\n",
       "      <th>...</th>\n",
       "      <th>B00DZDWMQO</th>\n",
       "      <th>B00WJOVCOS</th>\n",
       "      <th>B00PLMN77K</th>\n",
       "      <th>B00K9HID1C</th>\n",
       "      <th>B007IJ7T4G</th>\n",
       "      <th>B00005T3Q2</th>\n",
       "      <th>B000UXZUZC</th>\n",
       "      <th>B00A3YDYMO</th>\n",
       "      <th>B007EZPLFS</th>\n",
       "      <th>B00KG8K5CY</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>B00BJUE88U</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.227007</td>\n",
       "      <td>0.536770</td>\n",
       "      <td>0.120940</td>\n",
       "      <td>-0.410794</td>\n",
       "      <td>0.457204</td>\n",
       "      <td>0.233093</td>\n",
       "      <td>-0.382388</td>\n",
       "      <td>-0.286379</td>\n",
       "      <td>0.296789</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.478127</td>\n",
       "      <td>-0.035789</td>\n",
       "      <td>0.113693</td>\n",
       "      <td>0.244447</td>\n",
       "      <td>0.238238</td>\n",
       "      <td>0.437102</td>\n",
       "      <td>-0.435330</td>\n",
       "      <td>-0.315518</td>\n",
       "      <td>-0.398603</td>\n",
       "      <td>-0.228585</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>B004CLYJ2I</th>\n",
       "      <td>0.227007</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.197048</td>\n",
       "      <td>0.114000</td>\n",
       "      <td>-0.106718</td>\n",
       "      <td>0.012658</td>\n",
       "      <td>0.053251</td>\n",
       "      <td>-0.053830</td>\n",
       "      <td>0.003329</td>\n",
       "      <td>-0.018758</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.128787</td>\n",
       "      <td>0.004426</td>\n",
       "      <td>0.040800</td>\n",
       "      <td>0.168907</td>\n",
       "      <td>-0.006907</td>\n",
       "      <td>0.165175</td>\n",
       "      <td>-0.160562</td>\n",
       "      <td>-0.063170</td>\n",
       "      <td>-0.160413</td>\n",
       "      <td>0.078161</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>B0047FHOWG</th>\n",
       "      <td>0.536770</td>\n",
       "      <td>0.197048</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.048075</td>\n",
       "      <td>-0.555567</td>\n",
       "      <td>0.476471</td>\n",
       "      <td>0.377522</td>\n",
       "      <td>-0.315182</td>\n",
       "      <td>-0.217280</td>\n",
       "      <td>0.258792</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.556603</td>\n",
       "      <td>-0.094140</td>\n",
       "      <td>0.270253</td>\n",
       "      <td>0.350146</td>\n",
       "      <td>0.191650</td>\n",
       "      <td>0.523225</td>\n",
       "      <td>-0.475881</td>\n",
       "      <td>-0.356653</td>\n",
       "      <td>-0.597963</td>\n",
       "      <td>-0.121720</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>B01GVSD3P8</th>\n",
       "      <td>0.120940</td>\n",
       "      <td>0.114000</td>\n",
       "      <td>0.048075</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.113845</td>\n",
       "      <td>0.015274</td>\n",
       "      <td>0.144336</td>\n",
       "      <td>-0.208152</td>\n",
       "      <td>-0.259086</td>\n",
       "      <td>-0.037067</td>\n",
       "      <td>...</td>\n",
       "      <td>0.176053</td>\n",
       "      <td>-0.110197</td>\n",
       "      <td>-0.327295</td>\n",
       "      <td>0.015651</td>\n",
       "      <td>0.190243</td>\n",
       "      <td>0.261688</td>\n",
       "      <td>-0.091145</td>\n",
       "      <td>-0.263297</td>\n",
       "      <td>-0.189933</td>\n",
       "      <td>-0.239870</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>B00MRL30N4</th>\n",
       "      <td>-0.410794</td>\n",
       "      <td>-0.106718</td>\n",
       "      <td>-0.555567</td>\n",
       "      <td>-0.113845</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.491910</td>\n",
       "      <td>-0.278920</td>\n",
       "      <td>0.375924</td>\n",
       "      <td>0.256135</td>\n",
       "      <td>-0.209184</td>\n",
       "      <td>...</td>\n",
       "      <td>0.364969</td>\n",
       "      <td>0.169450</td>\n",
       "      <td>-0.056782</td>\n",
       "      <td>-0.190132</td>\n",
       "      <td>-0.308019</td>\n",
       "      <td>-0.459661</td>\n",
       "      <td>0.454607</td>\n",
       "      <td>0.393408</td>\n",
       "      <td>0.437005</td>\n",
       "      <td>0.275098</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>B00005T3Q2</th>\n",
       "      <td>0.437102</td>\n",
       "      <td>0.165175</td>\n",
       "      <td>0.523225</td>\n",
       "      <td>0.261688</td>\n",
       "      <td>-0.459661</td>\n",
       "      <td>0.417252</td>\n",
       "      <td>0.389126</td>\n",
       "      <td>-0.435956</td>\n",
       "      <td>-0.249905</td>\n",
       "      <td>0.206576</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.366817</td>\n",
       "      <td>-0.181486</td>\n",
       "      <td>-0.008463</td>\n",
       "      <td>0.325333</td>\n",
       "      <td>0.355631</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.431524</td>\n",
       "      <td>-0.441591</td>\n",
       "      <td>-0.549834</td>\n",
       "      <td>-0.301187</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>B000UXZUZC</th>\n",
       "      <td>-0.435330</td>\n",
       "      <td>-0.160562</td>\n",
       "      <td>-0.475881</td>\n",
       "      <td>-0.091145</td>\n",
       "      <td>0.454607</td>\n",
       "      <td>-0.443760</td>\n",
       "      <td>-0.214391</td>\n",
       "      <td>0.370177</td>\n",
       "      <td>0.264729</td>\n",
       "      <td>-0.251588</td>\n",
       "      <td>...</td>\n",
       "      <td>0.395631</td>\n",
       "      <td>0.031990</td>\n",
       "      <td>-0.122320</td>\n",
       "      <td>-0.283234</td>\n",
       "      <td>-0.234176</td>\n",
       "      <td>-0.431524</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.339102</td>\n",
       "      <td>0.422228</td>\n",
       "      <td>0.201837</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>B00A3YDYMO</th>\n",
       "      <td>-0.315518</td>\n",
       "      <td>-0.063170</td>\n",
       "      <td>-0.356653</td>\n",
       "      <td>-0.263297</td>\n",
       "      <td>0.393408</td>\n",
       "      <td>-0.487402</td>\n",
       "      <td>-0.167348</td>\n",
       "      <td>0.414448</td>\n",
       "      <td>0.211174</td>\n",
       "      <td>-0.260400</td>\n",
       "      <td>...</td>\n",
       "      <td>0.302032</td>\n",
       "      <td>0.088581</td>\n",
       "      <td>0.027768</td>\n",
       "      <td>-0.100637</td>\n",
       "      <td>-0.321223</td>\n",
       "      <td>-0.441591</td>\n",
       "      <td>0.339102</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.443675</td>\n",
       "      <td>0.315100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>B007EZPLFS</th>\n",
       "      <td>-0.398603</td>\n",
       "      <td>-0.160413</td>\n",
       "      <td>-0.597963</td>\n",
       "      <td>-0.189933</td>\n",
       "      <td>0.437005</td>\n",
       "      <td>-0.403216</td>\n",
       "      <td>-0.283427</td>\n",
       "      <td>0.456954</td>\n",
       "      <td>0.225765</td>\n",
       "      <td>-0.113637</td>\n",
       "      <td>...</td>\n",
       "      <td>0.369925</td>\n",
       "      <td>0.098390</td>\n",
       "      <td>-0.023694</td>\n",
       "      <td>-0.274191</td>\n",
       "      <td>-0.317981</td>\n",
       "      <td>-0.549834</td>\n",
       "      <td>0.422228</td>\n",
       "      <td>0.443675</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.159616</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>B00KG8K5CY</th>\n",
       "      <td>-0.228585</td>\n",
       "      <td>0.078161</td>\n",
       "      <td>-0.121720</td>\n",
       "      <td>-0.239870</td>\n",
       "      <td>0.275098</td>\n",
       "      <td>-0.433708</td>\n",
       "      <td>-0.173629</td>\n",
       "      <td>0.399154</td>\n",
       "      <td>0.253099</td>\n",
       "      <td>-0.349948</td>\n",
       "      <td>...</td>\n",
       "      <td>0.023094</td>\n",
       "      <td>0.059307</td>\n",
       "      <td>0.346548</td>\n",
       "      <td>-0.029144</td>\n",
       "      <td>-0.423129</td>\n",
       "      <td>-0.301187</td>\n",
       "      <td>0.201837</td>\n",
       "      <td>0.315100</td>\n",
       "      <td>0.159616</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>9631 rows × 9631 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            B00BJUE88U  B004CLYJ2I  B0047FHOWG  B01GVSD3P8  B00MRL30N4  \\\n",
       "B00BJUE88U    1.000000    0.227007    0.536770    0.120940   -0.410794   \n",
       "B004CLYJ2I    0.227007    1.000000    0.197048    0.114000   -0.106718   \n",
       "B0047FHOWG    0.536770    0.197048    1.000000    0.048075   -0.555567   \n",
       "B01GVSD3P8    0.120940    0.114000    0.048075    1.000000   -0.113845   \n",
       "B00MRL30N4   -0.410794   -0.106718   -0.555567   -0.113845    1.000000   \n",
       "...                ...         ...         ...         ...         ...   \n",
       "B00005T3Q2    0.437102    0.165175    0.523225    0.261688   -0.459661   \n",
       "B000UXZUZC   -0.435330   -0.160562   -0.475881   -0.091145    0.454607   \n",
       "B00A3YDYMO   -0.315518   -0.063170   -0.356653   -0.263297    0.393408   \n",
       "B007EZPLFS   -0.398603   -0.160413   -0.597963   -0.189933    0.437005   \n",
       "B00KG8K5CY   -0.228585    0.078161   -0.121720   -0.239870    0.275098   \n",
       "\n",
       "            B0043RS864  B00O23IQ66  B01FLKIT4M  B005JLQL26  B00005N5WU  ...  \\\n",
       "B00BJUE88U    0.457204    0.233093   -0.382388   -0.286379    0.296789  ...   \n",
       "B004CLYJ2I    0.012658    0.053251   -0.053830    0.003329   -0.018758  ...   \n",
       "B0047FHOWG    0.476471    0.377522   -0.315182   -0.217280    0.258792  ...   \n",
       "B01GVSD3P8    0.015274    0.144336   -0.208152   -0.259086   -0.037067  ...   \n",
       "B00MRL30N4   -0.491910   -0.278920    0.375924    0.256135   -0.209184  ...   \n",
       "...                ...         ...         ...         ...         ...  ...   \n",
       "B00005T3Q2    0.417252    0.389126   -0.435956   -0.249905    0.206576  ...   \n",
       "B000UXZUZC   -0.443760   -0.214391    0.370177    0.264729   -0.251588  ...   \n",
       "B00A3YDYMO   -0.487402   -0.167348    0.414448    0.211174   -0.260400  ...   \n",
       "B007EZPLFS   -0.403216   -0.283427    0.456954    0.225765   -0.113637  ...   \n",
       "B00KG8K5CY   -0.433708   -0.173629    0.399154    0.253099   -0.349948  ...   \n",
       "\n",
       "            B00DZDWMQO  B00WJOVCOS  B00PLMN77K  B00K9HID1C  B007IJ7T4G  \\\n",
       "B00BJUE88U   -0.478127   -0.035789    0.113693    0.244447    0.238238   \n",
       "B004CLYJ2I   -0.128787    0.004426    0.040800    0.168907   -0.006907   \n",
       "B0047FHOWG   -0.556603   -0.094140    0.270253    0.350146    0.191650   \n",
       "B01GVSD3P8    0.176053   -0.110197   -0.327295    0.015651    0.190243   \n",
       "B00MRL30N4    0.364969    0.169450   -0.056782   -0.190132   -0.308019   \n",
       "...                ...         ...         ...         ...         ...   \n",
       "B00005T3Q2   -0.366817   -0.181486   -0.008463    0.325333    0.355631   \n",
       "B000UXZUZC    0.395631    0.031990   -0.122320   -0.283234   -0.234176   \n",
       "B00A3YDYMO    0.302032    0.088581    0.027768   -0.100637   -0.321223   \n",
       "B007EZPLFS    0.369925    0.098390   -0.023694   -0.274191   -0.317981   \n",
       "B00KG8K5CY    0.023094    0.059307    0.346548   -0.029144   -0.423129   \n",
       "\n",
       "            B00005T3Q2  B000UXZUZC  B00A3YDYMO  B007EZPLFS  B00KG8K5CY  \n",
       "B00BJUE88U    0.437102   -0.435330   -0.315518   -0.398603   -0.228585  \n",
       "B004CLYJ2I    0.165175   -0.160562   -0.063170   -0.160413    0.078161  \n",
       "B0047FHOWG    0.523225   -0.475881   -0.356653   -0.597963   -0.121720  \n",
       "B01GVSD3P8    0.261688   -0.091145   -0.263297   -0.189933   -0.239870  \n",
       "B00MRL30N4   -0.459661    0.454607    0.393408    0.437005    0.275098  \n",
       "...                ...         ...         ...         ...         ...  \n",
       "B00005T3Q2    1.000000   -0.431524   -0.441591   -0.549834   -0.301187  \n",
       "B000UXZUZC   -0.431524    1.000000    0.339102    0.422228    0.201837  \n",
       "B00A3YDYMO   -0.441591    0.339102    1.000000    0.443675    0.315100  \n",
       "B007EZPLFS   -0.549834    0.422228    0.443675    1.000000    0.159616  \n",
       "B00KG8K5CY   -0.301187    0.201837    0.315100    0.159616    1.000000  \n",
       "\n",
       "[9631 rows x 9631 columns]"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 모든 사용자 쌍에 대한 [코사인 유사도] 계산\n",
    "# user_latent_vectors = pd.DataFrame(model.P, index=model.index_user_id.values())\n",
    "# user_latent_vectors = user_latent_vectors.drop(black_id, errors='ignore')\n",
    "cosine_matrix = cosine_similarity(user_latent_matrix)\n",
    "\n",
    "# 유사도 DataFrame으로 변환 (인덱스와 칼럼에 user_id 할당)\n",
    "cosine_df = pd.DataFrame(cosine_matrix, index=user_latent_matrix.index, columns=user_latent_matrix.index)\n",
    "cosine_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save model results\n",
    "with open('/home/ryu/thesis/real_amazon/additional_var/1_gsu_data/FM_8_cosine_sim.pkl', 'wb') as f:\n",
    "    pickle.dump(cosine_df, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # 유사도 계산 결과 불러오기\n",
    "# similarity_matrix = pd.read_csv('/home/ryu/thesis/test_movielens/cosine_sim.csv', index_col=0)\n",
    "# similarity_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('/home/ryu/thesis/real_amazon/additional_var/1_gsu_data/FM_8_cosine_sim.pkl', 'rb') as f:\n",
    "    cosine_df = pickle.load(f)\n",
    "with open('/home/ryu/thesis/real_amazon/additional_var/1_gsu_data/FM_8_pearson_sim.pkl', 'rb') as f:\n",
    "    pearson_df = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 사용자별 유사도 상위 n명의 데이터만 가지고 사용자 유사도 평균 계산\n",
    "def average_similarity(similarity_matrix, user_ids, n):\n",
    "\n",
    "    top_n_similarities = np.sort(similarity_matrix, axis=1)[:, -n-1:-1] # sort and take the top n, excluding the self-similarity\n",
    "    average_similarities = np.mean(top_n_similarities, axis=1)\n",
    "\n",
    "    user_similarity_dict = {user_id: avg_sim for user_id, avg_sim in zip(user_ids, average_similarities)}\n",
    "    average_similarity_df = pd.DataFrame(list(user_similarity_dict.items()), columns=['user_id', 'similarity_index'])\n",
    "\n",
    "    return average_similarity_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:xlabel='similarity_index', ylabel='Density'>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 평균 유사도 결과 산출\n",
    "avg_sim = average_similarity(pearson_df, pearson_df.index, 10)\n",
    "# Distribution Visualization\n",
    "sns.distplot(avg_sim['similarity_index'])# Dist. viz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    9631.000000\n",
       "mean        0.587648\n",
       "std         0.169926\n",
       "min         0.185166\n",
       "25%         0.460851\n",
       "50%         0.600111\n",
       "75%         0.719810\n",
       "max         0.938210\n",
       "Name: similarity_index, dtype: float64"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 유사도 평균 분포 확인\n",
    "avg_sim['similarity_index'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 유사도 크기 순으로 나열\n",
    "sim_values = sorted(list(avg_sim['similarity_index']))\n",
    "\n",
    "# 사용자의 특정 비율에 해당하는 인덱스를 계산\n",
    "percentiles = [i for i in range(1, 51)]\n",
    "threshold_indices = [(100 - p) * len(sim_values) // 100 for p in percentiles]\n",
    "# print(threshold_indices)\n",
    "\n",
    "# 각 비율에 해당하는 threshold 값을 찾기.\n",
    "thresholds = [sim_values[len(sim_values)-i] for i in threshold_indices]\n",
    "# print(thresholds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Percentile 1% - Threshold: 0.219856\n",
      "Number of users below threshold: 97\n",
      "Percentile 2% - Threshold: 0.242235\n",
      "Number of users below threshold: 193\n",
      "Percentile 3% - Threshold: 0.258459\n",
      "Number of users below threshold: 289\n",
      "Percentile 4% - Threshold: 0.276783\n",
      "Number of users below threshold: 386\n",
      "Percentile 5% - Threshold: 0.289796\n",
      "Number of users below threshold: 482\n",
      "Percentile 6% - Threshold: 0.303560\n",
      "Number of users below threshold: 578\n",
      "Percentile 7% - Threshold: 0.315524\n",
      "Number of users below threshold: 675\n",
      "Percentile 8% - Threshold: 0.325989\n",
      "Number of users below threshold: 771\n",
      "Percentile 9% - Threshold: 0.337108\n",
      "Number of users below threshold: 867\n",
      "Percentile 10% - Threshold: 0.347908\n",
      "Number of users below threshold: 964\n",
      "Percentile 11% - Threshold: 0.357386\n",
      "Number of users below threshold: 1060\n",
      "Percentile 12% - Threshold: 0.366459\n",
      "Number of users below threshold: 1156\n",
      "Percentile 13% - Threshold: 0.376244\n",
      "Number of users below threshold: 1253\n",
      "Percentile 14% - Threshold: 0.383356\n",
      "Number of users below threshold: 1349\n",
      "Percentile 15% - Threshold: 0.391848\n",
      "Number of users below threshold: 1445\n",
      "Percentile 16% - Threshold: 0.399923\n",
      "Number of users below threshold: 1541\n",
      "Percentile 17% - Threshold: 0.408164\n",
      "Number of users below threshold: 1638\n",
      "Percentile 18% - Threshold: 0.416191\n",
      "Number of users below threshold: 1734\n",
      "Percentile 19% - Threshold: 0.423222\n",
      "Number of users below threshold: 1830\n",
      "Percentile 20% - Threshold: 0.429921\n",
      "Number of users below threshold: 1927\n",
      "Percentile 21% - Threshold: 0.437058\n",
      "Number of users below threshold: 2023\n",
      "Percentile 22% - Threshold: 0.442742\n",
      "Number of users below threshold: 2119\n",
      "Percentile 23% - Threshold: 0.449793\n",
      "Number of users below threshold: 2216\n",
      "Percentile 24% - Threshold: 0.455484\n",
      "Number of users below threshold: 2312\n",
      "Percentile 25% - Threshold: 0.460854\n",
      "Number of users below threshold: 2408\n",
      "Percentile 26% - Threshold: 0.467838\n",
      "Number of users below threshold: 2505\n",
      "Percentile 27% - Threshold: 0.474537\n",
      "Number of users below threshold: 2601\n",
      "Percentile 28% - Threshold: 0.480700\n",
      "Number of users below threshold: 2697\n",
      "Percentile 29% - Threshold: 0.486780\n",
      "Number of users below threshold: 2793\n",
      "Percentile 30% - Threshold: 0.492937\n",
      "Number of users below threshold: 2890\n",
      "Percentile 31% - Threshold: 0.499153\n",
      "Number of users below threshold: 2986\n",
      "Percentile 32% - Threshold: 0.503804\n",
      "Number of users below threshold: 3082\n",
      "Percentile 33% - Threshold: 0.509924\n",
      "Number of users below threshold: 3179\n",
      "Percentile 34% - Threshold: 0.514839\n",
      "Number of users below threshold: 3275\n",
      "Percentile 35% - Threshold: 0.519983\n",
      "Number of users below threshold: 3371\n",
      "Percentile 36% - Threshold: 0.525351\n",
      "Number of users below threshold: 3468\n",
      "Percentile 37% - Threshold: 0.531367\n",
      "Number of users below threshold: 3564\n",
      "Percentile 38% - Threshold: 0.537256\n",
      "Number of users below threshold: 3660\n",
      "Percentile 39% - Threshold: 0.542209\n",
      "Number of users below threshold: 3757\n",
      "Percentile 40% - Threshold: 0.547840\n",
      "Number of users below threshold: 3853\n",
      "Percentile 41% - Threshold: 0.553620\n",
      "Number of users below threshold: 3949\n",
      "Percentile 42% - Threshold: 0.559225\n",
      "Number of users below threshold: 4046\n",
      "Percentile 43% - Threshold: 0.565086\n",
      "Number of users below threshold: 4142\n",
      "Percentile 44% - Threshold: 0.570205\n",
      "Number of users below threshold: 4238\n",
      "Percentile 45% - Threshold: 0.576501\n",
      "Number of users below threshold: 4334\n",
      "Percentile 46% - Threshold: 0.580779\n",
      "Number of users below threshold: 4431\n",
      "Percentile 47% - Threshold: 0.585951\n",
      "Number of users below threshold: 4527\n",
      "Percentile 48% - Threshold: 0.591339\n",
      "Number of users below threshold: 4623\n",
      "Percentile 49% - Threshold: 0.595412\n",
      "Number of users below threshold: 4720\n",
      "Percentile 50% - Threshold: 0.600131\n",
      "Number of users below threshold: 4816\n"
     ]
    }
   ],
   "source": [
    "# 각 threshold에 대한 사용자 수와 비율을 계산\n",
    "users_dict = {}\n",
    "\n",
    "for percentile, threshold in zip(percentiles, thresholds):\n",
    "\n",
    "    gsu = [user for user, sim in zip(avg_sim['user_id'], avg_sim['similarity_index']) if sim < threshold]\n",
    "\n",
    "    print(f'Percentile {percentile}% - Threshold: {threshold:.6f}')\n",
    "    print(f'Number of users below threshold: {len(gsu)}')\n",
    "    # print(f'Proportion of users below threshold: {len(gsu) / len(avg_sim):.6f}\\n')\n",
    "    # print(f'Users below threshold: {gsu}\\n')\n",
    "\n",
    "    users_dict[f'{percentile}'] = gsu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save model results\n",
    "with open('/home/ryu/thesis/real_amazon/additional_var/1_gsu_data/FM_8_pearson_gsu.pkl', 'wb') as f:\n",
    "    pickle.dump(users_dict, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ryuvenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
