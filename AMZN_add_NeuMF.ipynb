{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current cuda device: 0\n"
     ]
    }
   ],
   "source": [
    "# í•„ìš”í•œ ëª¨ë“ˆ ë¶ˆëŸ¬ì˜¤ê¸°\n",
    "\n",
    "import os\n",
    "os.environ[\"CUDA_DEVICE_ORDER\"] = \"PCI_BUS_ID\"\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"1\"\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(action = 'ignore')\n",
    "\n",
    "import pickle\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "# Device configuration\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print('Current cuda device:', torch.cuda.current_device())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# RMSE ì¤€ë¹„\n",
    "\n",
    "def RMSE(y_true, y_pred):\n",
    "    return np.sqrt(np.mean((np.array(y_true) - np.array(y_pred))**2))\n",
    "\n",
    "\n",
    "# ëª¨ë¸ ì¤€ë¹„\n",
    "\n",
    "## 1. Bestseller\n",
    "def Biased_Bestseller(train_data, test_data):\n",
    "\n",
    "    train = train_data.copy()\n",
    "    test = test_data.copy()\n",
    "\n",
    "    # ì•„ì´í…œë³„ í‰ê·  í‰ì  ê³„ì‚°\n",
    "    rating_mean = train.groupby('item_id')['rating'].mean()\n",
    "    test = test.join(rating_mean, on='item_id', rsuffix='_item')\n",
    "\n",
    "    # ì „ì²´ í‰ê·  í‰ì  ê³„ì‚°\n",
    "    global_mean = train['rating'].mean()\n",
    "    test['rating_item'].fillna(train['rating'].mean(), inplace=True)\n",
    "\n",
    "    # ì‚¬ìš©ìë³„ í‰ê·  í‰ì \n",
    "    user_mean = train.groupby('user_id')['rating'].mean()\n",
    "    test = test.join(user_mean, on='user_id', rsuffix='_user')\n",
    "    \n",
    "    \n",
    "    test['predicted_rating'] = test['rating_item'] - global_mean + test['rating_user']\n",
    "\n",
    "    rmse_result = RMSE(test['rating'], test['predicted_rating'])\n",
    "\n",
    "    return rmse_result\n",
    "\n",
    "\n",
    "## 3. NeuMF\n",
    "\n",
    "# Dataset ìƒì„±\n",
    "class CustomDataset(Dataset):\n",
    "    def __init__(self, user_ids, item_ids, ratings, text_embeddings):\n",
    "        self.user_ids = torch.tensor(user_ids, dtype=torch.long)\n",
    "        self.item_ids = torch.tensor(item_ids, dtype=torch.long)\n",
    "        self.ratings = torch.tensor(ratings, dtype=torch.float)\n",
    "        self.text_embeddings = torch.tensor(text_embeddings, dtype=torch.float)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.ratings)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        return self.user_ids[idx], self.item_ids[idx], self.ratings[idx], self.text_embeddings[idx]\n",
    "\n",
    "class NeuMF(nn.Module):\n",
    "    def __init__(self, num_users, num_items, num_layers, embedding_size, num_factors, text_emb_size, dropout=None):\n",
    "        super().__init__()\n",
    "\n",
    "        self.dropout = dropout\n",
    "\n",
    "        # FM part\n",
    "        self.user_embedding_fm = nn.Embedding(num_users, num_factors)\n",
    "        self.item_embedding_fm = nn.Embedding(num_items, num_factors)\n",
    "\n",
    "        # self.w_0 = nn.Parameter(torch.zeros(1))  # global bias\n",
    "        self.w = nn.Parameter(torch.Tensor(num_factors * 2 + text_emb_size))  # íŠ¹ì„±ë³„ ê°€ì¤‘ì¹˜\n",
    "        self.v = nn.Parameter(torch.Tensor(num_factors * 2 + text_emb_size, embedding_size))  # ì ì¬ ìš”ì¸ ê°€ì¤‘ì¹˜\n",
    "\n",
    "        # MLP part\n",
    "        self.user_embedding_mlp = nn.Embedding(num_users, embedding_size * (2 ** (num_layers - 1)))\n",
    "        self.item_embedding_mlp = nn.Embedding(num_items, embedding_size * (2 ** (num_layers - 1)))\n",
    "\n",
    "        mlp_input_size = embedding_size * (2 ** (num_layers - 1)) * 2 + text_emb_size\n",
    "\n",
    "        layers = []\n",
    "        for i in range(num_layers):\n",
    "            output_size = embedding_size * (2 ** (num_layers - i - 1))\n",
    "            if dropout:\n",
    "                layers.append(nn.Dropout(p=self.dropout))\n",
    "            layers.append(nn.Linear(mlp_input_size, output_size))\n",
    "            layers.append(nn.ReLU())\n",
    "            mlp_input_size = output_size\n",
    "        \n",
    "        self.mlp_layers = nn.Sequential(*layers)\n",
    "\n",
    "        # Final prediction layer\n",
    "        # final_layer_input_size = embedding_size + output_size + text_emb_size\n",
    "        self.final_layer = nn.Linear(222, 1)\n",
    "\n",
    "        self._init_weight_()\n",
    "\n",
    "    def _init_weight_(self):\n",
    "        # Initialize weights here\n",
    "        nn.init.normal_(self.user_embedding_fm.weight, std=0.01)\n",
    "        nn.init.normal_(self.item_embedding_fm.weight, std=0.01)\n",
    "        nn.init.normal_(self.user_embedding_mlp.weight, std=0.01)\n",
    "        nn.init.normal_(self.item_embedding_mlp.weight, std=0.01)\n",
    "\n",
    "        nn.init.normal_(self.w, std=0.01)\n",
    "        nn.init.normal_(self.v, std=0.01)\n",
    "\n",
    "        for layer in self.mlp_layers:\n",
    "            if isinstance(layer, nn.Linear):\n",
    "                nn.init.kaiming_normal_(self.final_layer.weight)\n",
    "        \n",
    "        nn.init.kaiming_normal_(self.final_layer.weight)\n",
    "    \n",
    "    def forward(self, user_input, item_input, text_input):\n",
    "        # FM part\n",
    "        user_emb_mf = self.user_embedding_fm(user_input)\n",
    "        item_emb_mf = self.item_embedding_fm(item_input)\n",
    "\n",
    "        x = torch.cat([user_emb_mf, item_emb_mf, text_input], dim=1)\n",
    "        # print(x.shape)\n",
    "\n",
    "        # 1ì°¨ ìƒí˜¸ì‘ìš©: ê° ì‚¬ìš©ìì™€ ì•„ì´í…œì˜ ê°€ì¤‘ì¹˜ë¥¼ ê³±í•˜ê³ , ê·¸ ê²°ê³¼ë¥¼ ëª¨ë‘ ë”í•¨\n",
    "        linear_terms = torch.sum(x * self.w, dim=1)\n",
    "\n",
    "        # print(linear_terms.shape)\n",
    "\n",
    "        # 2ì°¨ ìƒí˜¸ì‘ìš©\n",
    "        interactions = 0.5 * torch.sum(\n",
    "            torch.pow(torch.matmul(x, self.v), 2) - torch.matmul(torch.pow(x, 2), torch.pow(self.v, 2)), dim=1)\n",
    "        \n",
    "        # print(interactions.shape)\n",
    "\n",
    "\n",
    "        # ì˜ˆì¸¡ê°’ ê³„ì‚°\n",
    "        # predict = self.w_0 + linear_terms + interactions\n",
    "        linear_terms = linear_terms.unsqueeze(-1)\n",
    "        interactions = interactions.unsqueeze(-1)\n",
    "        predict = torch.cat([linear_terms, interactions], dim=1)\n",
    "\n",
    "        # pred2 = nn.Linear(2, 220)(predict)\n",
    "\n",
    "        # predict = predict.unsqueeze(-1)\n",
    "        # print(predict.shape)\n",
    "\n",
    "\n",
    "        # MLP part\n",
    "        user_emb_mlp = self.user_embedding_mlp(user_input)\n",
    "        item_emb_mlp = self.item_embedding_mlp(item_input)\n",
    "        mlp_vector = torch.cat([user_emb_mlp, item_emb_mlp, text_input], dim=1)\n",
    "        mlp_vector = self.mlp_layers(mlp_vector)\n",
    "\n",
    "        # print(mlp_vector.shape)\n",
    "\n",
    "        vector = torch.cat([predict, mlp_vector],dim=1)\n",
    "        # vector = torch.cat([pred2, mlp_vector], dim=1)\n",
    "\n",
    "        # print(vector.shape)\n",
    "    \n",
    "\n",
    "        rating = self.final_layer(vector)\n",
    "        return rating.squeeze()\n",
    "\n",
    "\n",
    "\n",
    "class EarlyStopping:\n",
    "    def __init__(self, patience=5, min_delta=0):\n",
    "        \"\"\"\n",
    "        Early stops the training if validation loss doesn't improve after a given patience.\n",
    "        \"\"\"\n",
    "        self.patience = patience\n",
    "        self.min_delta = min_delta\n",
    "        self.counter = 0\n",
    "        self.best_loss = None\n",
    "        self.early_stop = False\n",
    "\n",
    "    def __call__(self, val_loss):\n",
    "        if self.best_loss is None:\n",
    "            self.best_loss = val_loss\n",
    "        elif val_loss > self.best_loss - self.min_delta:\n",
    "            self.counter += 1\n",
    "            if self.counter >= self.patience:\n",
    "                self.early_stop = True\n",
    "        else:\n",
    "            self.best_loss = val_loss\n",
    "            self.counter = 0\n",
    "\n",
    "def train_and_evaluate(model, criterion, optimizer, train_loader, val_loader, epochs, scheduler=None, patience=5):\n",
    "    early_stopping = EarlyStopping(patience=patience)\n",
    "    train_rmse_hist = []\n",
    "    val_rmse_hist = []\n",
    "\n",
    "    best_val_rmse = float('inf')\n",
    "    best_epoch = 0\n",
    "    \n",
    "    for epoch in range(epochs):\n",
    "        model.train()\n",
    "        total_loss = 0\n",
    "        for user, item, rating, text in train_loader:\n",
    "            user, item, rating, text = user.to(device), item.to(device), rating.float().to(device), text.float().to(device)\n",
    "            \n",
    "            optimizer.zero_grad()\n",
    "            prediction = model(user, item, text)\n",
    "            loss = criterion(prediction.view(-1), rating.view(-1))\n",
    "            # loss = criterion(prediction, rating)\n",
    "            loss.backward()\n",
    "\n",
    "            # torch.nn.utils.clip_grad_norm_(model.parameters(), 2)\n",
    "            \n",
    "            optimizer.step()\n",
    "            \n",
    "            total_loss += loss.item()\n",
    "        \n",
    "        if scheduler:\n",
    "            scheduler.step()\n",
    "        \n",
    "        avg_loss = total_loss / len(train_loader)\n",
    "        train_rmse = torch.sqrt(torch.tensor(avg_loss))\n",
    "        train_rmse_hist.append(train_rmse.item())\n",
    "\n",
    "        val_rmse = evaluate(model, criterion, val_loader)\n",
    "        val_rmse_hist.append(val_rmse.item())\n",
    "\n",
    "        if val_rmse < best_val_rmse:\n",
    "            best_val_rmse = val_rmse\n",
    "            best_epoch = epoch + 1\n",
    "        \n",
    "        print(f\"Epoch {epoch+1}/{epochs}, Average Loss: {avg_loss:.6f}, Validation RMSE: {val_rmse:.6f}\")\n",
    "        \n",
    "        early_stopping(val_rmse)\n",
    "        if early_stopping.early_stop:\n",
    "            print(\"Early stopping triggered. Stopping training.\")\n",
    "            break\n",
    "\n",
    "    print(f\"Best Validation RMSE: {best_val_rmse:.8f} at Epoch {best_epoch}\")\n",
    "    return train_rmse_hist, val_rmse_hist, best_val_rmse\n",
    "\n",
    "\n",
    "def evaluate(model, criterion, val_loader):\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        total_loss = 0\n",
    "        for user, item, rating, text in val_loader:\n",
    "            user, item, rating, text = user.to(device), item.to(device), rating.float().to(device), text.float().to(device)\n",
    "            prediction = model(user, item, text)\n",
    "            loss = criterion(prediction.view(-1), rating.view(-1))\n",
    "            # loss = criterion(prediction, rating)\n",
    "            total_loss += loss.item()\n",
    "    avg_loss = total_loss / len(val_loader)\n",
    "    return torch.sqrt(torch.tensor(avg_loss))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ì‹¤í—˜ ì¤€ë¹„\n",
    "\n",
    "# ë°ì´í„° ë¶ˆëŸ¬ì˜¤ê¸°\n",
    "ratings = pd.read_csv('/home/ryu/thesis/data/amazon/Amazon_ratings.csv')\n",
    "reviews = pd.read_csv('/home/ryu/thesis/data/amazon/Amazon_reviews.csv')\n",
    "\n",
    "ratings = ratings[['item_id', 'user_id', 'rating']]\n",
    "reviews = reviews[['item_id', 'user_id', 'text']]\n",
    "\n",
    "## ê¸°ë³¸ ì „ì²˜ë¦¬\n",
    "cnt = ratings.groupby('user_id').count()['rating']\n",
    "keys = cnt[cnt>3].keys()\n",
    "ratings = ratings[ratings['user_id'].isin(keys)]\n",
    "\n",
    "with open('/home/ryu/thesis/real_amazon/additional_var/sbert_emb.pickle', 'rb') as f:\n",
    "    embeddings = pickle.load(f)\n",
    "\n",
    "emb = pd.DataFrame(embeddings)\n",
    "\n",
    "data = pd.merge(ratings, reviews, how='left', left_on=['user_id', 'item_id'], right_on=['user_id', 'item_id'])\n",
    "data = pd.concat([data, emb], axis=1)\n",
    "\n",
    "## train, test set ë‚˜ëˆ„ê¸°\n",
    "x = data.copy()\n",
    "y = data['user_id']\n",
    "ratings_train, ratings_test = train_test_split(x, test_size=0.25, stratify=y, random_state=84)\n",
    "\n",
    "## Black Sheep ì‚¬ìš©ì ëª©ë¡ ë¶ˆëŸ¬ì˜¤ê¸°\n",
    "with open('/home/ryu/thesis/real_amazon/black_id.pkl', 'rb') as f:\n",
    "    black = pickle.load(f)\n",
    "\n",
    "## train, test ì—ì„œ black sheep ì‚¬ìš©ìë§Œ ì¶”ì¶œ\n",
    "black_train = ratings_train[ratings_train['user_id'].isin(black)]\n",
    "black_test = ratings_test[ratings_test['user_id'].isin(black)]\n",
    "black_all = ratings[ratings['user_id'].isin(black)]\n",
    "\n",
    "## ì‚¬ìš©ì ìˆ˜ êµ¬í•˜ê¸° (ì´í›„ ê°€ì¤‘í‰ê·  ìœ„í•¨)\n",
    "entire_pop = ratings.user_id.nunique()      # ì „ì²´ ì‚¬ìš©ì ìˆ˜\n",
    "black_pop = len(black)                      # Black Sheep ì‚¬ìš©ì ìˆ˜\n",
    "rest_pop = entire_pop - black_pop           # ì „ì²´ - black sheep = white & gray ì‚¬ìš©ì ìˆ˜\n",
    "\n",
    "## black sheep ì œê±° ë°ì´í„°\n",
    "ratings_train = ratings_train[~ratings_train['user_id'].isin(black)]\n",
    "ratings_test = ratings_test[~ratings_test['user_id'].isin(black)]\n",
    "ratings = ratings[~ratings['user_id'].isin(black)]\n",
    "\n",
    "## ì‚¬ìš©ì IDì™€ ì˜í™” IDë¥¼ ì—°ì†ì ì¸ ì¸ë±ìŠ¤ë¡œ ë§¤í•‘\n",
    "user_to_index = {user: idx for idx, user in enumerate(ratings[\"user_id\"].unique())}\n",
    "item_to_index = {item: idx for idx, item in enumerate(ratings[\"item_id\"].unique())}\n",
    "\n",
    "## NeuMFëŠ” ë§µí•‘ëœ idë¥¼ ì‚¬ìš©í•˜ê¸° ë•Œë¬¸ì— ë¯¸ë¦¬ ë³€í™˜\n",
    "ratings_train['user_id_conv'] = ratings_train.user_id.map(user_to_index)\n",
    "ratings_train['item_id_conv'] = ratings_train.item_id.map(item_to_index)\n",
    "ratings_test['user_id_conv'] = ratings_test.user_id.map(user_to_index)\n",
    "ratings_test['item_id_conv'] = ratings_test.item_id.map(item_to_index)\n",
    "\n",
    "## White Sheep ëŒ€ìƒ MF ì‹¤í—˜ ê²°ê³¼ ë¶ˆëŸ¬ì˜¤ê¸° (NeuMF ì‹¤í—˜ ì‹œ ì‚¬ìš©)\n",
    "with open('/home/ryu/thesis/real_amazon/additional_var/White_FM/84c_White FM.pkl', 'rb') as f:\n",
    "    white_results_loaded = pickle.load(f)\n",
    "\n",
    "## Open saved user_gsu_dict (Gray Sheep id ë¶ˆëŸ¬ì˜¤ê¸°)\n",
    "with open('/home/ryu/thesis/real_amazon/additional_var/1_gsu_data/FM_84_cosine_gsu.pkl', 'rb') as f:\n",
    "    gray_dict = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*--*--*--*--*--*--*--*--*--*--*--*--*--*--*--*--*--*--*--*--*--*--*--*--*--*--*\n",
      "Black Bestseller RMSE (trained with only black_train): 1.2977171777421705\n",
      "*--*--*--*--*--*--*--*--*--*--*--*--*--*--*--*--*--*--*--*--*--*--*--*--*--*--*\n",
      "**************************************************\n",
      "                     10% ì‹¤í—˜ ì‹œì‘                \n",
      "**************************************************\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10% Black Bestseller RMSE (trained with white_train): 1.155138642682192\n",
      "Epoch 1/50, Average Loss: 3.395843, Validation RMSE: 1.062168\n",
      "Epoch 2/50, Average Loss: 1.102363, Validation RMSE: 1.060741\n",
      "Epoch 3/50, Average Loss: 1.101958, Validation RMSE: 1.060612\n",
      "Epoch 4/50, Average Loss: 1.101910, Validation RMSE: 1.062780\n",
      "Epoch 5/50, Average Loss: 1.102041, Validation RMSE: 1.060504\n",
      "Epoch 6/50, Average Loss: 1.101123, Validation RMSE: 1.060430\n",
      "Epoch 7/50, Average Loss: 1.101147, Validation RMSE: 1.060714\n",
      "Epoch 8/50, Average Loss: 1.101667, Validation RMSE: 1.060735\n",
      "Epoch 9/50, Average Loss: 1.100816, Validation RMSE: 1.060324\n",
      "Epoch 10/50, Average Loss: 1.100241, Validation RMSE: 1.060371\n",
      "Epoch 11/50, Average Loss: 1.099918, Validation RMSE: 1.060354\n",
      "Epoch 12/50, Average Loss: 1.100565, Validation RMSE: 1.060318\n",
      "Epoch 13/50, Average Loss: 1.099190, Validation RMSE: 1.060419\n",
      "Epoch 14/50, Average Loss: 1.099483, Validation RMSE: 1.060298\n",
      "Epoch 15/50, Average Loss: 1.099903, Validation RMSE: 1.060440\n",
      "Epoch 16/50, Average Loss: 1.099392, Validation RMSE: 1.060425\n",
      "Epoch 17/50, Average Loss: 1.099389, Validation RMSE: 1.060294\n",
      "Epoch 18/50, Average Loss: 1.100359, Validation RMSE: 1.060342\n",
      "Epoch 19/50, Average Loss: 1.100049, Validation RMSE: 1.060322\n",
      "Epoch 20/50, Average Loss: 1.099366, Validation RMSE: 1.060368\n",
      "Early stopping triggered. Stopping training.\n",
      "Best Validation RMSE: 1.06029415 at Epoch 17\n",
      "10% NeuMF RMSE: 1.0602941513061523\n",
      "10% NeuMF weighted RMSE (w/ White Sheep): 1.0313322973178367\n",
      "10% NeuMF weighted RMSE (w/ Black Sheep): 1.0947881662203591\n",
      "                10% ì‹¤í—˜ ë                 \n",
      "**************************************************\n",
      "                     15% ì‹¤í—˜ ì‹œì‘                \n",
      "**************************************************\n",
      "15% Black Bestseller RMSE (trained with white_train): 1.1596612635231978\n",
      "Epoch 1/50, Average Loss: 2.623645, Validation RMSE: 1.053670\n",
      "Epoch 2/50, Average Loss: 1.103647, Validation RMSE: 1.053610\n",
      "Epoch 3/50, Average Loss: 1.103396, Validation RMSE: 1.053649\n",
      "Epoch 4/50, Average Loss: 1.102080, Validation RMSE: 1.053689\n",
      "Epoch 5/50, Average Loss: 1.102776, Validation RMSE: 1.055125\n",
      "Early stopping triggered. Stopping training.\n",
      "Best Validation RMSE: 1.05360997 at Epoch 2\n",
      "15% NeuMF RMSE: 1.0536099672317505\n",
      "15% NeuMF weighted RMSE (w/ White Sheep): 1.0377727210280234\n",
      "15% NeuMF weighted RMSE (w/ Black Sheep): 1.099215756546741\n",
      "                15% ì‹¤í—˜ ë                 \n",
      "**************************************************\n",
      "                     20% ì‹¤í—˜ ì‹œì‘                \n",
      "**************************************************\n",
      "20% Black Bestseller RMSE (trained with white_train): 1.163147562543809\n",
      "Epoch 1/50, Average Loss: 2.257679, Validation RMSE: 1.062334\n",
      "Epoch 2/50, Average Loss: 1.114829, Validation RMSE: 1.062495\n",
      "Epoch 3/50, Average Loss: 1.114096, Validation RMSE: 1.063328\n",
      "Epoch 4/50, Average Loss: 1.114102, Validation RMSE: 1.062236\n",
      "Epoch 5/50, Average Loss: 1.113334, Validation RMSE: 1.062873\n",
      "Epoch 6/50, Average Loss: 1.113874, Validation RMSE: 1.062482\n",
      "Epoch 7/50, Average Loss: 1.114039, Validation RMSE: 1.061992\n",
      "Epoch 8/50, Average Loss: 1.113238, Validation RMSE: 1.062361\n",
      "Epoch 9/50, Average Loss: 1.112770, Validation RMSE: 1.061876\n",
      "Epoch 10/50, Average Loss: 1.113420, Validation RMSE: 1.061942\n",
      "Epoch 11/50, Average Loss: 1.112223, Validation RMSE: 1.061833\n",
      "Epoch 12/50, Average Loss: 1.111696, Validation RMSE: 1.061841\n",
      "Epoch 13/50, Average Loss: 1.111570, Validation RMSE: 1.061963\n",
      "Epoch 14/50, Average Loss: 1.112082, Validation RMSE: 1.061883\n",
      "Early stopping triggered. Stopping training.\n",
      "Best Validation RMSE: 1.06183338 at Epoch 11\n",
      "20% NeuMF RMSE: 1.061833381652832\n",
      "20% NeuMF weighted RMSE (w/ White Sheep): 1.0439447185933015\n",
      "20% NeuMF weighted RMSE (w/ Black Sheep): 1.1038361451442749\n",
      "                20% ì‹¤í—˜ ë                 \n",
      "**************************************************\n",
      "                     25% ì‹¤í—˜ ì‹œì‘                \n",
      "**************************************************\n",
      "25% Black Bestseller RMSE (trained with white_train): 1.1680156988885724\n",
      "Epoch 1/50, Average Loss: 2.213474, Validation RMSE: 1.073101\n",
      "Epoch 2/50, Average Loss: 1.134535, Validation RMSE: 1.072993\n",
      "Epoch 3/50, Average Loss: 1.134178, Validation RMSE: 1.072934\n",
      "Epoch 4/50, Average Loss: 1.133954, Validation RMSE: 1.072891\n",
      "Epoch 5/50, Average Loss: 1.134079, Validation RMSE: 1.072832\n",
      "Epoch 6/50, Average Loss: 1.133554, Validation RMSE: 1.072803\n",
      "Epoch 7/50, Average Loss: 1.133221, Validation RMSE: 1.073379\n",
      "Epoch 8/50, Average Loss: 1.133341, Validation RMSE: 1.072742\n",
      "Epoch 9/50, Average Loss: 1.133270, Validation RMSE: 1.072815\n",
      "Epoch 10/50, Average Loss: 1.132754, Validation RMSE: 1.073448\n",
      "Epoch 11/50, Average Loss: 1.132927, Validation RMSE: 1.072696\n",
      "Epoch 12/50, Average Loss: 1.131822, Validation RMSE: 1.072780\n",
      "Epoch 13/50, Average Loss: 1.132287, Validation RMSE: 1.072708\n",
      "Epoch 14/50, Average Loss: 1.132563, Validation RMSE: 1.072690\n",
      "Epoch 15/50, Average Loss: 1.132020, Validation RMSE: 1.072692\n",
      "Epoch 16/50, Average Loss: 1.132104, Validation RMSE: 1.072697\n",
      "Epoch 17/50, Average Loss: 1.132021, Validation RMSE: 1.072725\n",
      "Early stopping triggered. Stopping training.\n",
      "Best Validation RMSE: 1.07269001 at Epoch 14\n",
      "25% NeuMF RMSE: 1.0726900100708008\n",
      "25% NeuMF weighted RMSE (w/ White Sheep): 1.0504353755319955\n",
      "25% NeuMF weighted RMSE (w/ Black Sheep): 1.1081601938935737\n",
      "                25% ì‹¤í—˜ ë                 \n",
      "**************************************************\n",
      "                     30% ì‹¤í—˜ ì‹œì‘                \n",
      "**************************************************\n",
      "30% Black Bestseller RMSE (trained with white_train): 1.1762724875660586\n",
      "Epoch 1/50, Average Loss: 1.944906, Validation RMSE: 1.077191\n",
      "Epoch 2/50, Average Loss: 1.137596, Validation RMSE: 1.076050\n",
      "Epoch 3/50, Average Loss: 1.137584, Validation RMSE: 1.076611\n",
      "Epoch 4/50, Average Loss: 1.137151, Validation RMSE: 1.076094\n",
      "Epoch 5/50, Average Loss: 1.136535, Validation RMSE: 1.076809\n",
      "Early stopping triggered. Stopping training.\n",
      "Best Validation RMSE: 1.07604969 at Epoch 2\n",
      "30% NeuMF RMSE: 1.0760496854782104\n",
      "30% NeuMF weighted RMSE (w/ White Sheep): 1.0597368403472038\n",
      "30% NeuMF weighted RMSE (w/ Black Sheep): 1.1137869000948435\n",
      "                30% ì‹¤í—˜ ë                 \n",
      "**************************************************\n",
      "                     35% ì‹¤í—˜ ì‹œì‘                \n",
      "**************************************************\n",
      "35% Black Bestseller RMSE (trained with white_train): 1.1863049954626872\n",
      "Epoch 1/50, Average Loss: 2.014580, Validation RMSE: 1.069562\n",
      "Epoch 2/50, Average Loss: 1.133810, Validation RMSE: 1.069729\n",
      "Epoch 3/50, Average Loss: 1.133476, Validation RMSE: 1.069363\n",
      "Epoch 4/50, Average Loss: 1.133054, Validation RMSE: 1.069351\n",
      "Epoch 5/50, Average Loss: 1.133748, Validation RMSE: 1.069539\n",
      "Epoch 6/50, Average Loss: 1.134041, Validation RMSE: 1.069699\n",
      "Epoch 7/50, Average Loss: 1.133158, Validation RMSE: 1.070165\n",
      "Early stopping triggered. Stopping training.\n",
      "Best Validation RMSE: 1.06935072 at Epoch 4\n",
      "35% NeuMF RMSE: 1.0693507194519043\n",
      "35% NeuMF weighted RMSE (w/ White Sheep): 1.0684186487562028\n",
      "35% NeuMF weighted RMSE (w/ Black Sheep): 1.118003649962007\n",
      "                35% ì‹¤í—˜ ë                 \n",
      "**************************************************\n",
      "                     40% ì‹¤í—˜ ì‹œì‘                \n",
      "**************************************************\n",
      "40% Black Bestseller RMSE (trained with white_train): 1.2000391917325133\n",
      "Epoch 1/50, Average Loss: 1.782101, Validation RMSE: 1.059503\n",
      "Epoch 2/50, Average Loss: 1.128731, Validation RMSE: 1.061062\n",
      "Epoch 3/50, Average Loss: 1.127836, Validation RMSE: 1.059453\n",
      "Epoch 4/50, Average Loss: 1.127804, Validation RMSE: 1.059353\n",
      "Epoch 5/50, Average Loss: 1.127432, Validation RMSE: 1.059168\n",
      "Epoch 6/50, Average Loss: 1.127257, Validation RMSE: 1.060083\n",
      "Epoch 7/50, Average Loss: 1.127438, Validation RMSE: 1.059064\n",
      "Epoch 8/50, Average Loss: 1.127474, Validation RMSE: 1.059042\n",
      "Epoch 9/50, Average Loss: 1.127106, Validation RMSE: 1.059036\n",
      "Epoch 10/50, Average Loss: 1.127025, Validation RMSE: 1.059014\n",
      "Epoch 11/50, Average Loss: 1.126125, Validation RMSE: 1.059037\n",
      "Epoch 12/50, Average Loss: 1.126066, Validation RMSE: 1.059005\n",
      "Epoch 13/50, Average Loss: 1.126468, Validation RMSE: 1.059056\n",
      "Epoch 14/50, Average Loss: 1.126065, Validation RMSE: 1.059075\n",
      "Epoch 15/50, Average Loss: 1.126661, Validation RMSE: 1.059001\n",
      "Epoch 16/50, Average Loss: 1.126352, Validation RMSE: 1.059039\n",
      "Epoch 17/50, Average Loss: 1.126482, Validation RMSE: 1.059001\n",
      "Epoch 18/50, Average Loss: 1.126287, Validation RMSE: 1.059223\n",
      "Epoch 19/50, Average Loss: 1.126802, Validation RMSE: 1.059022\n",
      "Epoch 20/50, Average Loss: 1.126514, Validation RMSE: 1.059071\n",
      "Early stopping triggered. Stopping training.\n",
      "Best Validation RMSE: 1.05900061 at Epoch 17\n",
      "40% NeuMF RMSE: 1.0590006113052368\n",
      "40% NeuMF weighted RMSE (w/ White Sheep): 1.078356416572576\n",
      "40% NeuMF weighted RMSE (w/ Black Sheep): 1.1218288892858341\n",
      "                40% ì‹¤í—˜ ë                 \n",
      "**************************************************\n",
      "                     45% ì‹¤í—˜ ì‹œì‘                \n",
      "**************************************************\n",
      "45% Black Bestseller RMSE (trained with white_train): 1.2159868057978391\n",
      "Epoch 1/50, Average Loss: 1.654365, Validation RMSE: 1.056930\n",
      "Epoch 2/50, Average Loss: 1.122190, Validation RMSE: 1.056867\n",
      "Epoch 3/50, Average Loss: 1.121524, Validation RMSE: 1.056804\n",
      "Epoch 4/50, Average Loss: 1.121221, Validation RMSE: 1.056983\n",
      "Epoch 5/50, Average Loss: 1.121550, Validation RMSE: 1.056756\n",
      "Epoch 6/50, Average Loss: 1.121326, Validation RMSE: 1.057369\n",
      "Epoch 7/50, Average Loss: 1.120893, Validation RMSE: 1.056763\n",
      "Epoch 8/50, Average Loss: 1.120967, Validation RMSE: 1.056711\n",
      "Epoch 9/50, Average Loss: 1.121054, Validation RMSE: 1.056889\n",
      "Epoch 10/50, Average Loss: 1.120705, Validation RMSE: 1.056678\n",
      "Epoch 11/50, Average Loss: 1.120179, Validation RMSE: 1.056683\n",
      "Epoch 12/50, Average Loss: 1.119797, Validation RMSE: 1.056677\n",
      "Epoch 13/50, Average Loss: 1.120008, Validation RMSE: 1.056677\n",
      "Epoch 14/50, Average Loss: 1.119713, Validation RMSE: 1.056699\n",
      "Epoch 15/50, Average Loss: 1.120113, Validation RMSE: 1.056704\n",
      "Epoch 16/50, Average Loss: 1.119735, Validation RMSE: 1.056686\n",
      "Early stopping triggered. Stopping training.\n",
      "Best Validation RMSE: 1.05667746 at Epoch 12\n",
      "45% NeuMF RMSE: 1.0566774606704712\n",
      "45% NeuMF weighted RMSE (w/ White Sheep): 1.089841256260716\n",
      "45% NeuMF weighted RMSE (w/ Black Sheep): 1.1262160988362284\n",
      "                45% ì‹¤í—˜ ë                 \n",
      "**************************************************\n",
      "                     50% ì‹¤í—˜ ì‹œì‘                \n",
      "**************************************************\n",
      "50% Black Bestseller RMSE (trained with white_train): 1.2264752507554866\n",
      "Epoch 1/50, Average Loss: 1.584938, Validation RMSE: 1.060824\n",
      "Epoch 2/50, Average Loss: 1.122287, Validation RMSE: 1.060838\n",
      "Epoch 3/50, Average Loss: 1.122349, Validation RMSE: 1.060665\n",
      "Epoch 4/50, Average Loss: 1.121908, Validation RMSE: 1.063313\n",
      "Epoch 5/50, Average Loss: 1.122104, Validation RMSE: 1.060218\n",
      "Epoch 6/50, Average Loss: 1.121741, Validation RMSE: 1.061256\n",
      "Epoch 7/50, Average Loss: 1.121896, Validation RMSE: 1.060531\n",
      "Epoch 8/50, Average Loss: 1.122385, Validation RMSE: 1.060636\n",
      "Early stopping triggered. Stopping training.\n",
      "Best Validation RMSE: 1.06021786 at Epoch 5\n",
      "50% NeuMF RMSE: 1.0602178573608398\n",
      "50% NeuMF weighted RMSE (w/ White Sheep): 1.0993845523537147\n",
      "50% NeuMF weighted RMSE (w/ Black Sheep): 1.131091417467235\n",
      "                50% ì‹¤í—˜ ë                 \n"
     ]
    }
   ],
   "source": [
    "# ì‹¤í—˜ ì‹œì‘\n",
    "\n",
    "## 1. ê²°ê³¼ ì €ì¥í•  ë”•ì…”ë„ˆë¦¬ ìƒì„±\n",
    "\n",
    "white_fm = {}\n",
    "bestseller = {}\n",
    "weighted_bestseller = {}\n",
    "gray_bs = {}\n",
    "weighted_gray_bs = {}\n",
    "gray_fm = {}\n",
    "weighted_gray_fm = {}\n",
    "neumf = {}\n",
    "weighted_neumf = {}\n",
    "\n",
    "blk_bs = {}\n",
    "blk_weighted_bestseller = {}\n",
    "blk_weighted_gray_bs = {}\n",
    "blk_weighted_gray_fm = {}\n",
    "blk_weighted_neumf = {}\n",
    "\n",
    "## 2. Black Sheep ì‹¤í—˜ (trained with only black_train set; gray sheep ê¸°ì¤€ì— ë”°ë¼ ë³€í•¨ ì—†ê¸° ë•Œë¬¸ì— ë¯¸ë¦¬ ê³„ì‚°)\n",
    "blk_only_bestseller = Biased_Bestseller(black_train, black_test)\n",
    "print('*--*--*--*--*--*--*--*--*--*--*--*--*--*--*--*--*--*--*--*--*--*--*--*--*--*--*')\n",
    "print(f'Black Bestseller RMSE (trained with only black_train): {blk_only_bestseller}')\n",
    "print('*--*--*--*--*--*--*--*--*--*--*--*--*--*--*--*--*--*--*--*--*--*--*--*--*--*--*')\n",
    "\n",
    "## 3. ê¸°ì¤€ë³„ë¡œ gray sheep id ê°€ì ¸ì™€ì„œ ì‹¤í—˜\n",
    "\n",
    "test_list = [str(n) for n in range(10, 51, 5)]\n",
    "\n",
    "for thresh in test_list:\n",
    "\n",
    "    \n",
    "    gray_idx = gray_dict[thresh]    # thresh%ì— í•´ë‹¹í•˜ëŠ” Gray sheep ì‚¬ìš©ì id ê°€ì ¸ì˜¤ê¸°\n",
    "    white_rmse = white_results_loaded[thresh]    # thresh%ì— í•´ë‹¹í•˜ëŠ” White Sheep MF ê²°ê³¼ ê°€ì ¸ì˜¤ê¸° (NeuMF ì‹¤í—˜ ì‹œì—ë§Œ ì‚¬ìš©!)\n",
    "\n",
    "    print('**************************************************')\n",
    "    print(f'                     {thresh}% ì‹¤í—˜ ì‹œì‘                ')\n",
    "    print('**************************************************')\n",
    "\n",
    "\n",
    "    # white, gray sheep ì‚¬ìš©ì ë¶„ë¦¬\n",
    "    white = ratings[~ratings['user_id'].isin(gray_idx)]\n",
    "    gray = ratings[ratings['user_id'].isin(gray_idx)]\n",
    "\n",
    "    white_train = ratings_train[~ratings_train['user_id'].isin(gray_idx)]\n",
    "    white_test = ratings_test[~ratings_test['user_id'].isin(gray_idx)]\n",
    "\n",
    "    gray_train = ratings_train[ratings_train['user_id'].isin(gray_idx)]\n",
    "    gray_test = ratings_test[ratings_test['user_id'].isin(gray_idx)]\n",
    "\n",
    "    # NeuMF ë°ì´í„° ì¤€ë¹„\n",
    "    gray_new_idx = []\n",
    "    for g in gray_idx:\n",
    "        gray_new_idx.append(user_to_index[g])\n",
    "\n",
    "    neumf_gray_train = ratings_train[ratings_train['user_id_conv'].isin(gray_new_idx)]\n",
    "    neumf_gray_test = ratings_test[ratings_test['user_id_conv'].isin(gray_new_idx)]\n",
    "\n",
    "\n",
    "    #### 0. Black Sheep Bestseller (trained with White Sheep train set)\n",
    "    blk_bestseller = Bestseller(white_train, black_test)\n",
    "\n",
    "    print(f'{thresh}% Black Bestseller RMSE (trained with white_train): {blk_bestseller}')\n",
    "    blk_bs[f'{thresh}'] = blk_bestseller\n",
    "\n",
    "\n",
    "    # #### 5. Gray NeuMF ####\n",
    "\n",
    "    # í•˜ì´í¼íŒŒë¼ë¯¸í„° ì„¤ì •\n",
    "    num_users = len(set(data.user_id)) + 1\n",
    "    num_items = len(set(data.item_id)) + 1\n",
    "    num_layers=3\n",
    "    embedding_size = 220\n",
    "    num_factors = 220\n",
    "    text_emb_size = 384\n",
    "    epochs = 50\n",
    "    batch_size = 32\n",
    "    patience = 3\n",
    "\n",
    "    # ë°ì´í„° ë¡œë” ì •ì˜ \n",
    "    train_text_embeddings = emb.iloc[ratings_train['user_id_conv']].values\n",
    "    test_text_embeddings = emb.iloc[ratings_test['user_id_conv']].values\n",
    "\n",
    "    train_dataset = CustomDataset(\n",
    "        user_ids = neumf_gray_train['user_id_conv'].values,\n",
    "        item_ids = neumf_gray_train['item_id_conv'].values,\n",
    "        ratings = neumf_gray_train['rating'].values.astype(np.float32),\n",
    "        text_embeddings = train_text_embeddings\n",
    "    )\n",
    "    test_dataset = CustomDataset(\n",
    "        user_ids = neumf_gray_test['user_id_conv'].values,\n",
    "        item_ids = neumf_gray_test['item_id_conv'].values,\n",
    "        ratings = neumf_gray_test['rating'].values.astype(np.float32),\n",
    "        text_embeddings = test_text_embeddings\n",
    "    )\n",
    "\n",
    "    train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, num_workers=4)\n",
    "    test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False, num_workers=4)\n",
    "\n",
    "    # ëª¨ë¸ ì¸ìŠ¤í„´ìŠ¤ ìƒì„±\n",
    "    model = NeuMF(num_users, num_items, num_layers, embedding_size, num_factors, text_emb_size)\n",
    "\n",
    "    # ì†ì‹¤ í•¨ìˆ˜ì™€ ì˜µí‹°ë§ˆì´ì € ì„¤ì •\n",
    "    criterion = nn.MSELoss()\n",
    "    optimizer = optim.SGD(model.parameters(), lr=0.0014, weight_decay=0.015)\n",
    "    # optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "    scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=10, gamma=0.1)\n",
    "\n",
    "    model.to(device)\n",
    "    criterion.to(device)\n",
    "\n",
    "    train_rmse, val_rmse, best_RMSE = train_and_evaluate(model, criterion, optimizer, train_loader, test_loader, epochs, scheduler, patience)\n",
    "\n",
    "    print(f'{thresh}% NeuMF RMSE: {best_RMSE.item()}')\n",
    "    neumf[f'{thresh}'] = best_RMSE.item()\n",
    "    \n",
    "\n",
    "    # white sheep trained, black sheep tested\n",
    "    weighted_gray_neumf = (blk_bestseller * (black_pop/entire_pop)) + (white_rmse * ((rest_pop-len(gray_idx))/entire_pop)) + (best_RMSE.item() * (len(gray_idx)/entire_pop))\n",
    "    print(f'{thresh}% NeuMF weighted RMSE (w/ White Sheep): {weighted_gray_neumf}')\n",
    "    weighted_neumf[f'{thresh}'] = weighted_gray_neumf\n",
    "\n",
    "    # black sheep trained, black sheep tested\n",
    "    blk_weighted_gray_neumf = (blk_only_bestseller * (black_pop/entire_pop)) + (white_rmse * ((rest_pop-len(gray_idx))/entire_pop)) + (best_RMSE.item() * (len(gray_idx)/entire_pop))\n",
    "    print(f'{thresh}% NeuMF weighted RMSE (w/ Black Sheep): {blk_weighted_gray_neumf}')\n",
    "    blk_weighted_neumf[f'{thresh}'] = blk_weighted_gray_neumf\n",
    "\n",
    "\n",
    "\n",
    "    print(f'                {thresh}% ì‹¤í—˜ ë                 ')\n",
    "\n",
    "\n",
    "# ----------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "               ì‹¤í—˜ ê²°ê³¼ ì €ì¥ ì™„ë£Œ ğŸ˜               \n"
     ]
    }
   ],
   "source": [
    "# ì‹¤í—˜ ê²°ê³¼ ì €ì¥\n",
    "with open('/home/ryu/thesis/real_amazon/additional_var/Gray_NeuMF/84c_NeuMF.pkl', 'wb') as f:\n",
    "    pickle.dump(neumf, f)\n",
    "with open('/home/ryu/thesis/real_amazon/additional_var/Gray_NeuMF/84c_Weighted NeuMF.pkl', 'wb') as f:\n",
    "    pickle.dump(weighted_neumf, f)\n",
    "with open('/home/ryu/thesis/real_amazon/additional_var/Gray_NeuMF/84c_Weighted NeuMF Black.pkl', 'wb') as f:\n",
    "    pickle.dump(blk_weighted_neumf, f)\n",
    "\n",
    "\n",
    "print(f'               ì‹¤í—˜ ê²°ê³¼ ì €ì¥ ì™„ë£Œ ğŸ˜               ')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ryuvenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
